{
  "excluded": [
    "GridHelper",
    "PlaneGeometry",
    "BufferGeometry"
  ],
  "hashindex_prefix":"vectors_hashIndex_",
  "excludedSyncTables": ["graph", "tabs", "docs"],
  "dbName": "fileGraphDB",
  "dbStores": {
    "text_stats": {
      "keyPath": "fileId",
      "indexes": [
        { "name": "lastUpdated", "keyPath": "lastUpdated" }
      ]
    },
    "directories": { "keyPath": "id" },
    "files": { "keyPath": "id" },
    "graph": { "keyPath": "uuid" },
    "summaries": { "keyPath": "fileId" },
    "tabs": { "keyPath": "docId" },
    "docs": { "keyPath": "docId" },
    "peers": {
      "keyPath": "peerId",
      "indexes": [
        { "name": "status", "keyPath": "status" },
        { "name": "lastAttempt", "keyPath": "lastAttempt" }
      ]
    },
    "vectors": {
      "keyPath": "id",
      "vectorConfig": {
        "dimensions": 384,
        "hyperplanes": 10,
        "numPlanes": 5,
        "vectorPath": "embedding",
        "hashIndexSuffix": "_hashIndex"
      }
    },
    "vectors_hashIndex": {
    }
  },
  "vector_docs_query_limit":5,
  "apiConfig": {
    "endpoints": {
      "development": "http://localhost:8787",
      "production": "https://lumi.kak2594.workers.dev/"
    },
    "timeout" : 20000,
    "max_input_tokens": 4000,
    "models": {
      "open": {
        "nousresearch/hermes-3-llama-3.1-405b:free": {
          "provider": "OPEN",
          "endpoint": "https://openrouter.ai/api/v1/chat/completions",
          "headers": {
            "HTTP-Referer": "https://lumi.kak2594.workers.dev",
            "X-Title": "Lumi AI Assistant"
          },
          "parameters": {
            "model": "nousresearch/hermes-3-llama-3.1-405b:free",
            "temperature": 0.7,
            "max_tokens": 2000,
            "stream": true
          }
        }
      },
     "gemini": {
  "gemini-pro": {
    "provider": "GEMINI",
    "endpoint": "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:streamGenerateContent",
    "parameters": {
      "temperature": 0.7,
      "maxOutputTokens": 2000,
      "stream": true
    }
  }
},
      "groq": {
        "mixtral-8x7b-32768": {
          "provider": "GROQ",
          "endpoint": "https://api.groq.com/openai/v1/chat/completions",
          "parameters": {
            "model": "mixtral-8x7b-32768",
            "temperature": 1,
            "max_tokens": 1024,
            "top_p": 1,
            "stream": true,
            "stop": null
          }
        }
      },
      "cerebras": {
        "llama3.1-8b": {
          "provider": "CEREBRAS",
          "endpoint": "https://api.cerebras.ai/v1/chat/completions",
          "parameters": {
            "model": "llama3.1-8b",
            "temperature": 0,
            "max_tokens": -1,
            "top_p": 1,
            "stream": true,
            "seed": 0
          }
        }
      }
    }
  },
  "providerOrder": [ "GROQ","GEMINI","CEREBRAS"]
}